{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b24947c-cf93-4fa9-bda7-f259c60745e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.prompts import PromptTemplate,ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.agents import Tool, initialize_agent, create_openai_functions_agent, AgentExecutor\n",
    "from langchain.agents.agent import RunnableAgent\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import gradio as gr\n",
    "from gtts import gTTS\n",
    "import tempfile\n",
    "import base64\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2f4ec-584c-4b52-84cb-14bc2548d4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d805a4-16eb-4fc3-bcf7-4c46955c6ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAi API key found and looks good so far!\n",
      "ORS API key found and looks good so far!\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ORS_API_KEY = os.getenv(\"ORS_API_KEY\")\n",
    "\n",
    "# Check the key\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"No OpenAI API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not OPENAI_API_KEY.startswith(\"sk-proj-\"):\n",
    "    print(\"An OpenAI API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif OPENAI_API_KEY.strip() != OPENAI_API_KEY:\n",
    "    print(\"An OpenAI API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"OpenAi API key found and looks good so far!\")\n",
    "    \n",
    "if not ORS_API_KEY:\n",
    "    print(\"No ORS API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif ORS_API_KEY.strip() != ORS_API_KEY:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"ORS API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cfe0fd3f-47ac-4882-a5bb-6496b7bbed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SETUP ===\n",
    "DATASET_PATH = \"AutoRAG_Dataset\"\n",
    "manual_path = os.path.join(DATASET_PATH, \"car_manuals\", \"manuals.json\")\n",
    "weather_path = os.path.join(DATASET_PATH, \"weather_data\", \"weather_data.csv\")\n",
    "poi_path = os.path.join(DATASET_PATH, \"poi_data\", \"poi_data.csv\")\n",
    "PROFILE_PATH = os.path.join(DATASET_PATH, \"driver_profiles\", \"profiles.json\")\n",
    "TELEMETRY_PATH = os.path.join(DATASET_PATH, \"telemetry\", \"telemetry_logs.csv\")\n",
    "VOICE_LOG_PATH = os.path.join(DATASET_PATH, \"voice_queries\", \"voice_queries.csv\")\n",
    "CALENDAR_PATH = os.path.join(DATASET_PATH, \"calendar_events\", \"calendar_events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b191484-f6f5-4242-8440-e50641b7c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VECTOR INDEX BUILDING FROM MULTIPLE SOURCES ===\n",
    "def build_vectorstore_from_multiple_sources(index_path=\"car_manual_index\"):\n",
    "    documents = []\n",
    "\n",
    "    \n",
    "    # Car Manuals\n",
    "    with open(manual_path) as f:\n",
    "        manuals = json.load(f)\n",
    "    for m in manuals:\n",
    "        documents.append(Document(\n",
    "            page_content=m[\"content\"],\n",
    "            metadata={\"type\": \"manual\", \"doc_id\": m[\"doc_id\"]}\n",
    "        ))\n",
    "\n",
    "\n",
    "    # QA Triplets\n",
    "    with open(\"AutoRAG_Dataset/qa_triplets/qa_pairs.json\") as f:\n",
    "        qas = json.load(f)\n",
    "    for qa in qas:\n",
    "        content = f\"Q: {qa['question']}\\nContext: {qa['retrieved_context']}\\nA: {qa['answer']}\"\n",
    "        documents.append(Document(\n",
    "            page_content=content,\n",
    "            metadata={\"type\": \"qa_triplet\", \"qa_id\": qa[\"qa_id\"]}\n",
    "        ))\n",
    "\n",
    "\n",
    "    # POI\n",
    "    poi_df = load_poi_data()\n",
    "    for _, row in poi_df.iterrows():\n",
    "        content = f\"{row['type']} - {row['name']} in {row['city']}, Rating: {row['rating']}, Distance: {row['distance_km']} km\"\n",
    "        documents.append(Document(\n",
    "            page_content=content,\n",
    "            metadata={\"type\": \"poi\", \"city\": row[\"city\"], \"poi_type\": row[\"type\"]}\n",
    "        ))\n",
    "\n",
    "    # === Helper ===\n",
    "    def format_saved_locations(locs):\n",
    "        return \"; \".join(locs)\n",
    "    \n",
    "    # === 1. Driver Profiles ===\n",
    "    with open(PROFILE_PATH) as f:\n",
    "        profiles = json.load(f)\n",
    "    \n",
    "    profile_lookup = {p[\"user_id\"]: p for p in profiles}\n",
    "    \n",
    "    for profile in profiles:\n",
    "        content = (\n",
    "            f\"This is information about user {profile['name']} (user ID: {profile['user_id']}). \"\n",
    "            f\"They are {profile['age']} years old and prefer {profile['preferred_music']} music. \"\n",
    "            f\"Their home address is {profile['home_address'].replace(chr(10), ', ')}, and they work at {profile['work_address'].replace(chr(10), ', ')}. \"\n",
    "            f\"Their driving style is {profile['driving_style']}. \"\n",
    "            f\"Saved locations include: {format_saved_locations(profile['saved_locations'])}.\"\n",
    "        )\n",
    "        documents.append(Document(page_content=content, metadata={\"type\": \"profile\", \"user_id\": profile['user_id']}))\n",
    "    \n",
    "    # === 2. Telemetry Logs ===\n",
    "    telemetry_df = pd.read_csv(TELEMETRY_PATH)\n",
    "    for user_id, user_df in tqdm(telemetry_df.groupby(\"user_id\"), desc=\"Processing telemetry\"):\n",
    "        profile = profile_lookup.get(user_id, {})\n",
    "        user_name = profile.get(\"name\", user_id)\n",
    "        summary = (\n",
    "            f\"Telemetry summary for user {user_name} (user ID: {user_id}). \"\n",
    "            f\"{len(user_df)} data points recorded across trips. \"\n",
    "            f\"Speed ranged from {user_df['speed_kmph'].min()} to {user_df['speed_kmph'].max()} km/h. \"\n",
    "            f\"Battery ranged from {user_df['battery_level_percent'].min()}% to {user_df['battery_level_percent'].max()}%. \"\n",
    "            f\"Tire pressure was typically around {user_df['tire_pressure_psi'].mean():.2f} PSI. \"\n",
    "            f\"Cabin temperature averaged {user_df['cabin_temp_c'].mean():.2f}Â°C.\"\n",
    "        )\n",
    "        documents.append(Document(page_content=summary, metadata={\"type\": \"telemetry\", \"user_id\": user_id}))\n",
    "\n",
    "    # === 3. Voice Queries ===\n",
    "    queries_df = pd.read_csv(VOICE_LOG_PATH)\n",
    "    for user_id, user_df in tqdm(queries_df.groupby(\"user_id\"), desc=\"Processing voice queries\"):\n",
    "        profile = profile_lookup.get(user_id, {})\n",
    "        user_name = profile.get(\"name\", user_id)\n",
    "        content = (\n",
    "            f\"Voice interaction history for user {user_name} (user ID: {user_id}): \"\n",
    "            f\"They asked the assistant the following types of queries: \"\n",
    "            f\"{'; '.join(user_df['query_text'].unique()[:10])}.\"\n",
    "        )\n",
    "        documents.append(Document(page_content=content, metadata={\"type\": \"voice_queries\", \"user_id\": user_id}))\n",
    "    \n",
    "    # === 4. Calendar Events ===\n",
    "    calendar_df = pd.read_csv(CALENDAR_PATH)\n",
    "    for user_id, user_df in tqdm(calendar_df.groupby(\"user_id\"), desc=\"Processing calendar\"):\n",
    "        profile = profile_lookup.get(user_id, {})\n",
    "        user_name = profile.get(\"name\", user_id)\n",
    "        events = \", \".join(user_df[\"title\"].unique())\n",
    "        content = (\n",
    "            f\"Calendar for user {user_name} (user ID: {user_id}): \"\n",
    "            f\"Scheduled events include: {events}. \"\n",
    "            f\"Typical durations are around {user_df['duration_minutes'].mean():.1f} minutes.\"\n",
    "        )\n",
    "        documents.append(Document(page_content=content, metadata={\"type\": \"calendar\", \"user_id\": user_id}))\n",
    "\n",
    "\n",
    "    # Embedding\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    split_docs = splitter.split_documents(documents)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    db = FAISS.from_documents(split_docs, embeddings)\n",
    "    db.save_local(index_path)\n",
    "    return db\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d83f79c5-fce9-46e5-8d6e-31f7e09bf83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DATA LOADING FUNCTIONS ===\n",
    "def load_weather_data():\n",
    "    return pd.read_csv(weather_path)\n",
    "\n",
    "def load_poi_data():\n",
    "    return pd.read_csv(poi_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "859ea390-f7a7-43cc-956b-2a03b82358cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Weather Tool ===\n",
    "class WeatherInput(BaseModel):\n",
    "    city: str\n",
    "\n",
    "@tool(\"get_weather\", args_schema=WeatherInput)\n",
    "def get_weather_tool(city: str) -> str:\n",
    "    \"\"\"Get current weather info for a city using Open-Meteo API.\"\"\"\n",
    "    url = f\"https://api.open-meteo.com/v1/forecast?latitude=40.71&longitude=-74.01&current_weather=true\"\n",
    "    response = requests.get(url)\n",
    "    if response.ok:\n",
    "        data = response.json()\n",
    "        weather = data['current_weather']\n",
    "        return f\"Current weather in {city}: {weather['temperature']}Â°C, Wind {weather['windspeed']} km/h.\"\n",
    "    return \"Sorry, unable to fetch weather.\"\n",
    "\n",
    "\n",
    "# === Navigation Tool ===\n",
    "class NavigationInput(BaseModel):\n",
    "    from_location: str\n",
    "    to_location: str\n",
    "    \n",
    "\n",
    "@tool(\"get_directions\", args_schema=NavigationInput)\n",
    "def get_directions_tool(from_location: str, to_location: str) -> str:\n",
    "    \"\"\"Get driving directions from one location to another using OpenRouteService.\"\"\"\n",
    "    def geocode(location: str) -> list:\n",
    "        geo_url = f\"https://api.openrouteservice.org/geocode/search\"\n",
    "        headers = {\n",
    "            \"Authorization\": ORS_API_KEY\n",
    "        }\n",
    "        params = {\n",
    "            \"api_key\": ORS_API_KEY,\n",
    "            \"text\": location,\n",
    "            \"size\": 1\n",
    "        }\n",
    "        resp = requests.get(geo_url, headers=headers, params=params)\n",
    "        try:\n",
    "            return resp.json()['features'][0]['geometry']['coordinates']\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Could not geocode '{location}': {resp.text}\")\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": ORS_API_KEY,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        from_coords = geocode(from_location)\n",
    "        to_coords = geocode(to_location)\n",
    "    except ValueError as e:\n",
    "        return str(e)\n",
    "\n",
    "    body = {\n",
    "        \"coordinates\": [from_coords, to_coords]\n",
    "    }\n",
    "\n",
    "    url = \"https://api.openrouteservice.org/v2/directions/driving-car\"\n",
    "    response = requests.post(url, headers=headers, json=body)\n",
    "\n",
    "    try:\n",
    "        data = response.json()\n",
    "    except:\n",
    "        return f\"Invalid JSON returned: {response.text}\"\n",
    "\n",
    "    if \"features\" not in data:\n",
    "        return f\"Unexpected response format:\\n{data}\"\n",
    "\n",
    "    try:\n",
    "        steps = data['features'][0]['properties']['segments'][0]['steps']\n",
    "        directions = \"\\n\".join([f\"{i+1}. {s['instruction']}\" for i, s in enumerate(steps)])\n",
    "        return \"Navigation Steps:\\n\" + directions\n",
    "    except Exception as e:\n",
    "        return f\"Failed to parse directions: {e}\\nFull response:\\n{data}\"\n",
    "\n",
    "\n",
    "# === User Profile Tool ===\n",
    "class UserProfileInput(BaseModel):\n",
    "    name: str\n",
    "\n",
    "@tool(\"get_user_profile\", args_schema=UserProfileInput)\n",
    "def get_user_profile_tool(name: str) -> str:\n",
    "    \"\"\"Retrieve driver profile based on name.\"\"\"\n",
    "    with open(PROFILE_PATH) as f:\n",
    "        profiles = json.load(f)\n",
    "\n",
    "    name = name.strip().lower()\n",
    "\n",
    "    for p in profiles:\n",
    "        if p['name'].split()[0].lower() == name:\n",
    "            return (\n",
    "                f\"User {p['name']}: {p['age']} yrs\\n\"\n",
    "                f\"Home: {p['home_address']}\\n\"\n",
    "                f\"Work: {p['work_address']}\\n\"\n",
    "                f\"Driving Style: {p['driving_style']}\\n\"\n",
    "                f\"Preferred Music: {p['preferred_music']}\\n\"\n",
    "                f\"Saved Locations:\\n- \" + \"\\n- \".join(p['saved_locations'])\n",
    "            )\n",
    "    \n",
    "    return \"User not found.\"\n",
    "\n",
    "\n",
    "# === RAG Retrieval Tool ===\n",
    "class RAGInput(BaseModel):\n",
    "    query: str\n",
    "\n",
    "@tool(\"smart_rag\", args_schema=RAGInput)\n",
    "def smart_rag_tool(query: str) -> str:\n",
    "    \"\"\"Answer queries using in-vehicle data including manuals, FAQs, and Points Of Interests, trip logs,Telemetry Logs,Voice Query History,Calander Events  .\"\"\"\n",
    "    vectorstore = FAISS.load_local(\"car_manual_index\", OpenAIEmbeddings(), allow_dangerous_deserialization=True)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    return \"\\n\".join([doc.page_content for doc in docs]) if docs else \"No relevant info found in the manual.\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LogFullInteractionInput(BaseModel):\n",
    "    name: str         # Full name input\n",
    "    query: str        # User's spoken/typed input\n",
    "    response: str     # LLM model's response\n",
    "\n",
    "@tool(\"log_user_interaction\", args_schema=LogFullInteractionInput)\n",
    "def log_user_interaction_tool(name: str, query: str, response: str) -> str:\n",
    "    \"\"\"Logs a user query and the corresponding model response.\"\"\"\n",
    "    # Load existing profiles to resolve name to user_id\n",
    "    with open(PROFILE_PATH) as f:\n",
    "        profiles = json.load(f)\n",
    "\n",
    "    name = name.strip().lower()\n",
    "    matched_user = next((p for p in profiles if name in p[\"name\"].lower()), None)\n",
    "    if not matched_user:\n",
    "        return f\"â ï¸ No user found matching name '{name}'\"\n",
    "\n",
    "    user_id = matched_user[\"user_id\"]\n",
    "    full_name = matched_user[\"name\"]\n",
    "    timestamp = datetime.utcnow().isoformat()\n",
    "    intent = query.strip().split()[0].lower() if query.strip() else \"unknown\"\n",
    "\n",
    "    log_entry = {\n",
    "        \"user_id\": user_id,\n",
    "        \"name\": full_name,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"query_text\": query,\n",
    "        \"response_text\": response,\n",
    "        \"intent\": intent\n",
    "    }\n",
    "\n",
    "    # Ensure file has header if it doesn't exist\n",
    "    file_exists = os.path.exists(VOICE_LOG_PATH)\n",
    "    with open(VOICE_LOG_PATH, \"a\", newline='') as f:\n",
    "        writer = csv.DictWriter(\n",
    "            f,\n",
    "            fieldnames=[\"user_id\", \"name\", \"timestamp\", \"query_text\", \"response_text\", \"intent\"]\n",
    "        )\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(log_entry)\n",
    "\n",
    "    return f\"â Logged interaction for {full_name} ({user_id})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a6a59fd-1a9a-419f-bda9-0e2cf7b06df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_executor():\n",
    "    tools = [\n",
    "        get_weather_tool,\n",
    "        get_directions_tool,\n",
    "        get_user_profile_tool,\n",
    "        smart_rag_tool,\n",
    "        log_user_interaction_tool\n",
    "    ]\n",
    "\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "            \"\"\"\n",
    "            You are AutoRAG++, an intelligent in-vehicle assistant for drivers.\n",
    "\n",
    "            You have access to various tools and a rich internal knowledge base powered by vector search. \n",
    "            The knowledge base contains multiple types of documents and data that you can retrieve and use to answer queries accurately and helpfully.\n",
    "            \n",
    "            Hereâs what your memory includes:\n",
    "            \n",
    "            ð **Car Manuals**: Detailed information about car parts, maintenance instructions, settings, and troubleshooting steps.\n",
    "            \n",
    "            ð¬ **QA Triplets**: Frequently asked questions from users with context and pre-generated answers.\n",
    "            \n",
    "            ð **Points of Interest (POIs)**: Places like restaurants, hospitals, and gas stations along with their type, location, rating, and distance.\n",
    "            \n",
    "            ð¤ **Driver Profiles**: Data about each user including name, age, home and work addresses, driving style, preferred music, and saved locations.\n",
    "            \n",
    "            ð **Telemetry Logs**: Trip-level data including speed, battery level, tire pressure, and cabin temperature over time for each user.\n",
    "            \n",
    "            ð£ï¸ **Voice Query History**: Past voice/text interactions made by users with associated timestamps and inferred intent.\n",
    "            \n",
    "            ð **Calendar Events**: Upcoming user events such as meetings or service appointments with location and time.\n",
    "            \n",
    "    \n",
    "            \n",
    "            ð ï¸ You also have access to tools that allow you to:\n",
    "            - Navigate between places using real-time routing\n",
    "            - Retrieve current weather\n",
    "            - Look up specific user profiles\n",
    "            - Log new user interactions (query + response)\n",
    "            - Retrieve relevant information using RAG (retrieval-augmented generation)\n",
    "            \n",
    "            ð¯ Your job is to use this knowledge and the tools to help the driver:\n",
    "            - Answer questions about car functionality or past trips\n",
    "            - Find POIs or weather in any location\n",
    "            - Understand driving stats or calendar reminders\n",
    "            - Act as a friendly voice assistant that logs every interaction\n",
    "            - Keep responses short, clear, and spoken in a natural way\n",
    "\n",
    "            You should log every user query and your response using the `log_user_interaction` tool. Provide the user's name, query, and your response.\n",
    "            Always try to personalize your responses using user-specific data and keep answers natural for speech (as your response will be read aloud).\n",
    "            \"\"\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "    ])\n",
    "\n",
    "    prompt = prompt.partial()\n",
    "\n",
    "    agent: RunnableAgent = create_openai_functions_agent(\n",
    "        llm=llm,\n",
    "        prompt=prompt,\n",
    "        tools=tools\n",
    "    )\n",
    "\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "    executor = AgentExecutor(\n",
    "        agent=agent,\n",
    "        tools=tools,\n",
    "        memory=memory,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    return executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa1aba1a-87a0-4479-abd3-a990cf3fd04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing telemetry: 100%|âââââââââââââââââââ| 50/50 [00:00<00:00, 6443.26it/s]\n",
      "Processing voice queries: 100%|ââââââââââââââ| 50/50 [00:00<00:00, 14899.84it/s]\n",
      "Processing calendar: 100%|âââââââââââââââââââ| 50/50 [00:00<00:00, 11881.88it/s]\n"
     ]
    }
   ],
   "source": [
    "build_vectorstore_from_multiple_sources(index_path=\"car_manual_index\")\n",
    "agent = get_agent_executor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06556bf0-cfe2-4329-a8a3-42ab7a530e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_weather` with `{'city': 'Atlanta'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mCurrent weather in Atlanta: 21.8Â°C, Wind 9.4 km/h.\u001b[0m\u001b[32;1m\u001b[1;3mThe weather in Atlanta today is about 22 degrees Celsius with a light wind of 9 kilometers per hour. Would you like to know anything else?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The weather in Atlanta today is about 22 degrees Celsius with a light wind of 9 kilometers per hour. Would you like to know anything else?\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\n",
    "    {\"input\": \"How is the weather in atlanta today?\"}\n",
    ")\n",
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76325d0-6525-4d8e-a41b-15f613d602c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "570efdac-0f9a-4d2f-abb3-c32ede88286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === UI ===\n",
    "def launch_ui(chain):\n",
    "    def respond(audio_file, text):\n",
    "        if text:\n",
    "            query = text\n",
    "        elif audio_file:\n",
    "            import speech_recognition as sr\n",
    "            recognizer = sr.Recognizer()\n",
    "            with sr.AudioFile(audio_file) as source:\n",
    "                audio = recognizer.record(source)\n",
    "            try:\n",
    "                query = recognizer.recognize_google(audio)\n",
    "            except sr.UnknownValueError:\n",
    "                return gr.update(value=\"\"), \"Sorry, I couldn't understand the audio.\", \"\"\n",
    "            except sr.RequestError:\n",
    "                return gr.update(value=\"\"), \"Speech recognition service error.\", \"\"\n",
    "        else:\n",
    "            return gr.update(value=\"\"), \"Please provide input.\", \"\"\n",
    "\n",
    "        result = chain.invoke({\"input\": query})[\"output\"]\n",
    "        \n",
    "\n",
    "        tts = gTTS(result)\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as f:\n",
    "            temp_audio_path = f.name\n",
    "            tts.save(temp_audio_path)\n",
    "\n",
    "        with open(temp_audio_path, \"rb\") as f:\n",
    "            audio_data = f.read()\n",
    "        audio_base64 = base64.b64encode(audio_data).decode(\"utf-8\")\n",
    "\n",
    "        audio_html = f\"\"\"\n",
    "        <audio id='response-audio' controls autoplay style='width:100%;'>\n",
    "            <source src='data:audio/mpeg;base64,{audio_base64}' type='audio/mpeg'>\n",
    "            Your browser does not support the audio element.\n",
    "        </audio>\n",
    "        <script>\n",
    "            const audio = document.getElementById(\"response-audio\");\n",
    "            if (audio) {{\n",
    "                audio.playbackRate = 1.5;\n",
    "                audio.play().catch(() => {{ console.warn(\"Autoplay blocked.\"); }});\n",
    "            }}\n",
    "        </script>\n",
    "        \"\"\"\n",
    "        return gr.update(value=\"\"), result, audio_html\n",
    "    \n",
    "    gr.Interface(\n",
    "        fn=respond,\n",
    "        inputs=[\n",
    "            gr.Audio(type=\"filepath\", label=\"ðï¸ Speak your query (or type below)\"),\n",
    "            gr.Textbox(label=\"âï¸ Or type your query\")\n",
    "        ],\n",
    "        outputs=[\n",
    "            gr.Textbox(label=\"âï¸\", interactive=True),\n",
    "            gr.Textbox(label=\"ð§  Response\", interactive=False),\n",
    "            gr.HTML(label=\"ð Audio Reply\")\n",
    "        ],\n",
    "        \n",
    "        title=\"ð NaviZen â A calm, reliable In-Vehicle voice co-pilot that understands you.\",\n",
    "        theme=\"soft\"\n",
    "    ).launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006c1e5-303a-44a7-bcd1-fd2c9201981b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f26ac221-86c0-4b3a-9565-ab53c25c4b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ð Building index and launching assistant...\n",
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === MAIN RUN ===\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ð Building index and launching assistant...\")\n",
    "    #build_vectorstore_from_multiple_sources(index_path=\"car_manual_index\")\n",
    "    weather_df = load_weather_data()\n",
    "    poi_df = load_poi_data()\n",
    "    rag_chain = get_agent_executor()\n",
    "    launch_ui(rag_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d9cf0e-85d0-4865-94e4-d47bf510d146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9c472b12-cb4c-43f1-965b-5994b288e934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openrouteservice in /Applications/anaconda3/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: requests>=2.0 in /Applications/anaconda3/lib/python3.12/site-packages (from openrouteservice) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Applications/anaconda3/lib/python3.12/site-packages (from requests>=2.0->openrouteservice) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/lib/python3.12/site-packages (from requests>=2.0->openrouteservice) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Applications/anaconda3/lib/python3.12/site-packages (from requests>=2.0->openrouteservice) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.12/site-packages (from requests>=2.0->openrouteservice) (2024.8.30)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "21542098-95cb-42b3-8131-6729d44c6fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gTTS\n",
      "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Applications/anaconda3/lib/python3.12/site-packages (from gTTS) (2.32.2)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in /Applications/anaconda3/lib/python3.12/site-packages (from gTTS) (8.1.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Applications/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.27->gTTS) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.27->gTTS) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Applications/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.27->gTTS) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.27->gTTS) (2024.8.30)\n",
      "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: gTTS\n",
      "Successfully installed gTTS-2.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0704c8c0-b0b8-47e8-8f23-82afd7ee8562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0.post1-cp312-cp312-macosx_14_0_arm64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /Applications/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /Applications/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (23.2)\n",
      "Downloading faiss_cpu-1.11.0.post1-cp312-cp312-macosx_14_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917fc803-3d2f-4755-a17e-a423137f0cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "918fdb19-5059-47f3-8ae0-80479be76a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Applications/anaconda3/lib/python3.12/site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Applications/anaconda3/lib/python3.12/site-packages (from tiktoken) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Applications/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Applications/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "Downloading tiktoken-0.9.0-cp312-cp312-macosx_11_0_arm64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50df9da1-e79d-414c-b431-669b19ac04df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jq\n",
      "  Downloading jq-1.10.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
      "Downloading jq-1.10.0-cp312-cp312-macosx_11_0_arm64.whl (426 kB)\n",
      "\u001b[2K   \u001b[90mââââââââââââââââââââââââââââââââââââââââ\u001b[0m \u001b[32m426.3/426.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: jq\n",
      "Successfully installed jq-1.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48472dfa-3b49-47cf-bfc7-74b6fcb05a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "!!pip install jq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
